{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time, json\n",
    "\n",
    "# Function to initialize the driver\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    return driver, wait\n",
    "\n",
    "# Function to login and verify OTP\n",
    "def login(driver, wait, phone_number, otp_file):\n",
    "    driver.get(\"https://dashboard.ambitio.club/admit-finder\")\n",
    "\n",
    "    phone_input = driver.find_element(By.CSS_SELECTOR, 'input[type=\"tel\"]')\n",
    "    phone_input.send_keys(phone_number)\n",
    "\n",
    "    send_button = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]')\n",
    "    send_button.click()\n",
    "\n",
    "    time.sleep(40)  # Wait for the OTP to arrive and be entered\n",
    "    with open(otp_file, \"r\") as file:\n",
    "        otp = file.read()\n",
    "    \n",
    "    otp_inputs = driver.find_elements(By.CSS_SELECTOR, 'input[type=\"tel\"]')\n",
    "    for i in range(6):\n",
    "        otp_inputs[i].send_keys(otp[i])\n",
    "\n",
    "    skip_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Skip\")]')))\n",
    "    skip_button.click()\n",
    "\n",
    "# Function to extract profile links\n",
    "def extract_profile_links(driver):\n",
    "    profile_links = []\n",
    "    grid_div = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.grid.mob\\\\:grid-cols-1.grid-cols-3\")))\n",
    "    profile_divs = grid_div.find_elements(By.CSS_SELECTOR, 'a.border')\n",
    "\n",
    "    for profile in profile_divs:\n",
    "        profile_link = profile.get_attribute('href')\n",
    "        profile_links.append(profile_link)\n",
    "    \n",
    "    return profile_links\n",
    "\n",
    "# Function to extract data from a profile\n",
    "def extract_profile_data(driver, wait, profile_link):\n",
    "    profile_data = {'link': profile_link}\n",
    "    driver.get(profile_link)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    name = driver.find_element(By.CSS_SELECTOR, 'p.font-primary-bold.text-primary.text-\\\\[1\\\\.1vw\\\\].whitespace-nowrap.truncate.mob\\\\:text-\\\\[3\\\\.6vw\\\\]').text\n",
    "    term = driver.find_element(By.CSS_SELECTOR, 'p.font-secondary-bold.text-\\\\[\\\\.93vw\\\\].mob\\\\:text-\\\\[3vw\\\\].text-granite').text\n",
    "    profile_data['name'] = name\n",
    "    profile_data['term'] = term\n",
    "    cards = driver.find_elements(By.CLASS_NAME, \"admitFinderDetailsCard\")\n",
    "    l = 0\n",
    "    for card in cards:\n",
    "        title = card.find_element(By.CLASS_NAME, \"admitFinderProfileSectionSubtitle\").text\n",
    "        if title == \"Test scores\":\n",
    "            profile_data['test_scores'] = extract_test_scores(wait)\n",
    "        elif title == \"Work Experience\":\n",
    "            profile_data['work_experience'], l = extract_work_experience(wait)\n",
    "        elif title == \"Education\":\n",
    "            profile_data['education'] = extract_education(wait, l)\n",
    "    applications_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//div[@class=\"flex items-center mob:justify-center gap-[.7vw] border-b-[2px]  border-whisper  px-[3vw] pb-[0.5vw] cursor-pointer mob:w-[50%] mob:pb-[2.5vw] \"]/p[text()=\"Applications\"]'))\n",
    "    )\n",
    "    applications_button.click()\n",
    "    # time.sleep(1)\n",
    "\n",
    "    # Extract university name, program, and status\n",
    "    applications = WebDriverWait(driver, 30).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.border-whisper.flex.items-center.justify-between.w-full.py-\\\\[1\\\\.6vw\\\\].mob\\\\:py-\\\\[4\\\\.154vw\\\\]')))\n",
    "    \n",
    "    applications_data = []\n",
    "\n",
    "    for app in applications:\n",
    "        university_name = app.find_element(By.CSS_SELECTOR, 'p.font-primary-medium').text\n",
    "        program = app.find_element(By.CSS_SELECTOR, 'p.font-secondary-medium').text\n",
    "        status = app.find_elements(By.TAG_NAME, \"p\")[-1].text\n",
    "\n",
    "        applications_data.append({\n",
    "            'University Name': university_name,\n",
    "            'Program': program,\n",
    "            'Status': status\n",
    "        })\n",
    "    profile_data['applications'] = applications_data\n",
    "    \n",
    "    return profile_data\n",
    "\n",
    "# Function to extract test scores\n",
    "def extract_test_scores(wait):\n",
    "    test_scores = []\n",
    "    blocks = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.flex.justify-between.pb-\\\\[\\\\.83vw\\\\].mob\\\\:pb-\\\\[3vw\\\\]\")))\n",
    "    \n",
    "    for block in blocks:\n",
    "        test_name = block.find_element(By.CSS_SELECTOR, \"p.admitFinderProfileItemsTitle\").text\n",
    "        score = block.find_element(By.CSS_SELECTOR, \"p.font-secondary-bold\").text\n",
    "        sub_scores = block.find_elements(By.CSS_SELECTOR, \"div.text-end p.font-secondary-bold\")\n",
    "        sub_scores_titles = block.find_elements(By.CSS_SELECTOR, \"div.text-end p.font-primary-regular\")\n",
    "        sub_scores_text = [sub.text for sub in sub_scores]\n",
    "        sub_scores_titles_text = [sub.text for sub in sub_scores_titles]\n",
    "\n",
    "        test_scores.append({\n",
    "            \"test_name\": test_name,\n",
    "            \"score\": score,\n",
    "            \"sub_scores_titles\": sub_scores_titles_text,\n",
    "            \"sub_scores\": sub_scores_text\n",
    "        })\n",
    "\n",
    "    return test_scores\n",
    "\n",
    "# Function to extract work experience\n",
    "def extract_work_experience(wait):\n",
    "    work_experience = []\n",
    "    blocks = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.flex.items-center.gap-\\\\[\\\\.5vw\\\\].mob\\\\:gap-\\\\[1\\\\.5vw\\\\].w-full\")))\n",
    "    \n",
    "    for block in blocks:\n",
    "        role = block.find_element(By.CSS_SELECTOR, \"p.admitFinderProfileItemsTitle.mob\\\\:w-\\\\[40vw\\\\]\").text\n",
    "        role_time = block.find_element(By.CSS_SELECTOR, \"p.font-secondary-semibold\").text\n",
    "        role_type = block.find_element(By.CSS_SELECTOR, \"p.font-primary-medium\").text\n",
    "        company = block.find_element(By.CSS_SELECTOR, \"p.font-secondary-bold \").text\n",
    "        \n",
    "        work_experience.append({\n",
    "            \"role\": role,\n",
    "            \"role_time\": role_time,\n",
    "            \"role_type\": role_type,\n",
    "            \"company\": company\n",
    "        })\n",
    "    l = len(blocks)\n",
    "\n",
    "    return work_experience, l\n",
    "\n",
    "# Function to extract education details\n",
    "def extract_education(wait, l=0):\n",
    "    education = []\n",
    "    blocks = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.flex.justify-between.mob\\\\:pt-\\\\[4\\\\.1vw\\\\]\")))\n",
    "    \n",
    "    for block in blocks[l:]:\n",
    "        try:\n",
    "            org = block.find_element(By.CSS_SELECTOR, \"p.admitFinderProfileItemsTitle\").text\n",
    "        except NoSuchElementException:\n",
    "            org = None\n",
    "        try:\n",
    "            level = block.find_element(By.CSS_SELECTOR, \"p.font-secondary-medium.text-granite\").text\n",
    "        except NoSuchElementException:\n",
    "            level = None\n",
    "        try:\n",
    "            grade_type = block.find_element(By.CSS_SELECTOR, \"p.font-primary-medium\").text\n",
    "        except NoSuchElementException:\n",
    "            grade_type = None\n",
    "        try:\n",
    "            grade = block.find_element(By.CSS_SELECTOR, \"p.font-secondary-bold\").text\n",
    "        except NoSuchElementException:\n",
    "            grade = None\n",
    "        try:\n",
    "            course = block.find_element(By.CSS_SELECTOR, \"p.font-secondary-semibold\").text\n",
    "        except NoSuchElementException:\n",
    "            course = None\n",
    "        \n",
    "        education.append({\n",
    "            \"org\": org,\n",
    "            \"level\": level,\n",
    "            \"grade_type\": grade_type,\n",
    "            \"grade\": grade,\n",
    "            \"course\": course\n",
    "        })\n",
    "\n",
    "    return education\n",
    "\n",
    "# Function to move to the next page\n",
    "def go_to_next_page(driver, wait):\n",
    "    next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[aria-label=\"Go to next page\"]')))\n",
    "    \n",
    "    # Scroll the page until the \"Next\" button is visible\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", next_button)\n",
    "    \n",
    "    # Wait a moment to ensure the button is fully visible and clickable\n",
    "    time.sleep(1)\n",
    "    \n",
    "    next_button.click()\n",
    "    wait.until(EC.staleness_of(next_button))  # Wait until the next page loads completely\n",
    "\n",
    "\n",
    "# Function to go back to the profiles page\n",
    "def go_back_to_profiles_page(driver, wait):\n",
    "    back_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.flex.w-max.items-center.mob\\\\:gap-\\\\[1\\\\.1vw\\\\].pl-\\\\[2\\\\.55vw\\\\].pt-\\\\[1\\\\.67vw\\\\].mob\\\\:pt-\\\\[4\\\\.1vw\\\\]')))\n",
    "    back_button.click()\n",
    "    wait.until(EC.staleness_of(back_button))  # Wait until the profiles page reloads\n",
    "\n",
    "# Main function to collect all profiles data across multiple pages\n",
    "def collect_all_profiles_data(driver, wait, start_page, end_page):\n",
    "    all_profiles_data = []\n",
    "    for i in range(start_page-1):\n",
    "        go_to_next_page(driver, wait)\n",
    "    \n",
    "    for page in range(start_page, end_page + 1):\n",
    "        time.sleep(1)\n",
    "        print(f\"Scraping page {page}\")\n",
    "        profile_links = extract_profile_links(driver)\n",
    "        \n",
    "        for profile_link in profile_links:\n",
    "            profile_data = extract_profile_data(driver, wait, profile_link)\n",
    "            all_profiles_data.append(profile_data)\n",
    "            go_back_to_profiles_page(driver, wait)\n",
    "            time.sleep(1)\n",
    "        \n",
    "        if page < end_page:\n",
    "            go_to_next_page(driver, wait)\n",
    "            \n",
    "    \n",
    "    return all_profiles_data\n",
    "\n",
    "# Function to save data as JSON\n",
    "def save_data_as_json(data, file_name):\n",
    "    try:\n",
    "        # Open the file in 'r+' mode, which allows reading and writing\n",
    "        with open(file_name, 'r+') as json_file:\n",
    "            try:\n",
    "                existing_data = json.load(json_file)  # Load existing data\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []  # If the file is empty or not a valid JSON, start with an empty list\n",
    "            \n",
    "            existing_data.extend(data)  # Append new data\n",
    "\n",
    "            # Move the file pointer to the beginning of the file\n",
    "            json_file.seek(0)\n",
    "\n",
    "            # Write the updated data and truncate the rest of the file content\n",
    "            json.dump(existing_data, json_file, indent=2)\n",
    "            json_file.truncate()\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it and write the data\n",
    "        with open(file_name, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "# Main script execution\n",
    "if __name__ == \"__main__\":\n",
    "    driver, wait = initialize_driver()\n",
    "    login(driver, wait, '7696884562', 'otp.txt')\n",
    "    \n",
    "    start_page = 21  # Set your starting page\n",
    "    end_page = 25    # Set your ending page\n",
    "    \n",
    "    all_profiles_data = collect_all_profiles_data(driver, wait, start_page, end_page)\n",
    "    print(json.dumps(all_profiles_data, indent=2))\n",
    "    \n",
    "    save_data_as_json(all_profiles_data, 'profiles_data.json')\n",
    "    \n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_test_scores(test_scores):\n",
    "    score_dict = {}\n",
    "    for test in test_scores:\n",
    "        test_name = test.get('test_name', '').lower().replace(\" \", \"_\")\n",
    "        score_dict[f'test_{test_name}_score'] = test.get('score', '')\n",
    "        for i, (sub_title, sub_score) in enumerate(zip(test.get('sub_scores_titles', []), test.get('sub_scores', []))):\n",
    "            score_dict[f'test_{test_name}_{sub_title.lower().replace(\" \", \"_\")}'] = sub_score\n",
    "    return score_dict\n",
    "\n",
    "def extract_work_experience(work_experience):\n",
    "    work_dict = {}\n",
    "    for i, work in enumerate(work_experience, start=1):\n",
    "        work_dict[f'company_{i}_role'] = work.get('role', '')\n",
    "        work_dict[f'company_{i}_role_time'] = work.get('role_time', '')\n",
    "        work_dict[f'company_{i}_role_type'] = work.get('role_type', '')\n",
    "        work_dict[f'company_{i}_name'] = work.get('company', '')\n",
    "    return work_dict\n",
    "\n",
    "def extract_education(education):\n",
    "    edu_dict = {}\n",
    "    for i, edu in enumerate(education, start=1):\n",
    "        edu_dict[f'education_{i}_organization'] = edu.get('org', '')\n",
    "        edu_dict[f'education_{i}_level'] = edu.get('level', '')\n",
    "        edu_dict[f'education_{i}_grade_type'] = edu.get('grade_type', '')\n",
    "        edu_dict[f'education_{i}_grade'] = edu.get('grade', '')\n",
    "        edu_dict[f'education_{i}_course'] = edu.get('course', '')\n",
    "    return edu_dict\n",
    "\n",
    "def extract_applications(applications):\n",
    "    app_dict = {}\n",
    "    for i, app in enumerate(applications, start=1):\n",
    "        app_dict[f'application_{i}_University'] = app.get('University Name', '')\n",
    "        app_dict[f'application_{i}_Program'] = app.get('Program', '')\n",
    "        app_dict[f'application_{i}_Status'] = app.get('Status', '')\n",
    "    return app_dict\n",
    "\n",
    "\n",
    "\n",
    "def flatten_user_data(user_data):\n",
    "    flattened_data = {}\n",
    "    flattened_data['name'] = user_data.get('name', '')\n",
    "    flattened_data['term'] = user_data.get('term', '')\n",
    "    flattened_data['profile_link'] = user_data.get('link', '')\n",
    "\n",
    "    if 'test_scores' in user_data:\n",
    "        flattened_data.update(extract_test_scores(user_data['test_scores']))\n",
    "    \n",
    "    if 'work_experience' in user_data:\n",
    "        flattened_data.update(extract_work_experience(user_data['work_experience']))\n",
    "\n",
    "    if 'education' in user_data:\n",
    "        flattened_data.update(extract_education(user_data['education']))\n",
    "\n",
    "    if 'applications' in user_data:\n",
    "        flattened_data.update(extract_applications(user_data['applications']))\n",
    "    \n",
    "    return flattened_data\n",
    "\n",
    "def convert_json_to_csv(json_filename, csv_filename):\n",
    "    with open(json_filename, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    flattened_data_list = [flatten_user_data(user) for user in json_data]\n",
    "    \n",
    "    # Get all unique keys for the CSV header and sort them\n",
    "    all_keys = set()\n",
    "    for data in flattened_data_list:\n",
    "        all_keys.update(data.keys())\n",
    "\n",
    "    all_keys.remove('name')\n",
    "    all_keys.remove('profile_link')\n",
    "    all_keys.remove('term')\n",
    "    \n",
    "    sorted_keys = ['name', 'profile_link', 'term'] + sorted(list(all_keys))\n",
    "\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=sorted_keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(flattened_data_list)\n",
    "\n",
    "# Run the conversion\n",
    "if __name__ == \"__main__\":\n",
    "    convert_json_to_csv('profiles_data.json', 'profiles_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
